{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700a88c6",
   "metadata": {},
   "source": [
    "# Project for UDA Assessment 4\n",
    "## Author: 02179784 (Mark Roberts)\n",
    "\n",
    "<B>Project Description:</B><BR>\n",
    "The objective of this project is to create a simple framework to test how well image classification models perform when presented with degraded images.  The idea is that different classification models can be swapped-in/out and tested with minimal changes.  Also, the type of image degradation - e.g. faded or noisy images - can be easily changed.\n",
    "\n",
    "In this particular implementation of the framework:\n",
    " - we use a model that has been pre-trained to classify non-degraded images with an accurancy of over 97%.<BR>\n",
    "    This model was created using the guidance provided in chapter 8 of [1], and is based on refining an already pretrained model.<BR>\n",
    "    The refining of the model has been omitted here as it took several hours to build this model!\n",
    " - all images used in the refining and testing of this model are cat and dog images taken from the Kaggle website: [Cat and Dog Images](https://kaggle.com/competitions/dogs-vs-cats/data).\n",
    " - testing will be performed using two types of image degradation:\n",
    "    1. uniform random noise, but this could be easily replaced by other noise patterns (e.g. Gaussian) if desired and\n",
    "    2. image fading, which is simulated by colour strength reduction.\n",
    " \n",
    "The testing image dataset consists of 2000 images - 1000 cat and 1000 dog images.\n",
    "\n",
    "\n",
    "<B>General Information:</B><BR>\n",
    " - This script was run on a Macbook Pro. with 16 GB of RAM, 3.1 GHz Quad-Core Intel Core i7.\n",
    " - The total run time of the Jupyter notebook was (approx) 1 hour and 20 minutes.\n",
    " - The Github repository for all code and datasets can be obtained by cloning the repository:<BR>\n",
    "              https://github.com/Mark12481632/UDA_Assessment_4_02179784_Roberts.git\n",
    " - The model used to classify the images is built on __TensorFlow__ and __Keras__.\n",
    " - __Altered images need to be saved to disk - so write permission for the notebook is required!!__\n",
    "    \n",
    "<B>References:</B><BR>\n",
    "    \n",
    "    [1] - Deep Learning with Python (Francios Chollet, Manning Publications, ISBN-13: 978-1617296864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256c1139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time = 2022-12-27 21:51:57.149530\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "import datetime\n",
    "\n",
    "e = datetime.datetime.now()\n",
    "\n",
    "print (\"Current date and time = %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea11217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 21:51:59.322999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load in the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input, Model, Sequential\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe14e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 21:52:05.650971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Location of non-noisy and noisy images:\n",
    "test_dir = \"./cats_vs_dogs/test\"\n",
    "test_altered_dir = \"./cats_vs_dogs/test_altered\"\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(180, 180), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712f62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that store accuracy and level of noise/fading in images\n",
    "noise_level = []\n",
    "accuracy = []\n",
    "sample_image = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29cebc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "63/63 [==============================] - 150s 2s/step - loss: 3.5702 - accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "# Test on Original images without any noise.\n",
    "# The image that was trained has been saved as \"feature_extraction_with_data_augmentation.keras\"\n",
    "\n",
    "test_model = load_model(\"feature_extraction_with_data_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "\n",
    "noise_level.append(0)                                          # Noise level saved\n",
    "accuracy.append(round(test_acc, 4))                            # Model accuracy saved\n",
    "sample_image.append(io.imread(test_dir + \"/cat/cat.1500.jpg\")) # Sample image saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60726d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_image(src_img, dst_img, noise_level):\n",
    "    \"\"\"\n",
    "    This function takes a single image 'src_img' and addes noise to it as defoned\n",
    "    by the 'noise_level' parameter.  The noisy image is then written to 'dst_img'.\n",
    "    Nothing is returned.\n",
    "    \"\"\"\n",
    "    # Read in image into Numpy array\n",
    "    img = io.imread(src_img)\n",
    "\n",
    "    # Generate a matrix of random data (0=>1) in same shape as image\n",
    "    noise_matrix = np.random.uniform(low=0, high=1.0,\n",
    "                                     size=(img.shape[0]*img.shape[1])).reshape(img.shape[0], img.shape[1])\n",
    "    # Where does the data exceed the \"threshold\"\n",
    "    noise_matrix = np.where(noise_matrix < noise_level)\n",
    "\n",
    "    # Remove colours from image at the given random points\n",
    "    for (x,y) in zip(noise_matrix[0], noise_matrix[1]):\n",
    "        img[x, y, 0:3] = 0\n",
    "\n",
    "    # Save the image\n",
    "    io.imsave(dst_img, img)\n",
    "\n",
    "\n",
    "def fade_image(src_img, dst_img, fade_level):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Read in image into Numpy array\n",
    "    img = io.imread(src_img)\n",
    "\n",
    "    # Fade image by reducing all colours by given factor\n",
    "    img = np.uint8(img * fade_level)\n",
    "\n",
    "    # Save the image\n",
    "    io.imsave(dst_img, img)\n",
    "\n",
    "\n",
    "\n",
    "def create_altered_images(src_dir, dst_dir, ftn, level):\n",
    "    \"\"\"\n",
    "    This function copies over the images from a 'src_dir' to a 'dst_dir' after performing some\n",
    "    function on them - e.g. adding noise or fading the image.  The 'level' determines the degree/level\n",
    "    of noise (0->1) or fade (0->1).\n",
    "    Nothing is returned.\n",
    "    \"\"\"\n",
    "    all_cats = os.listdir(src_dir + \"/cat\")\n",
    "    all_dogs = os.listdir(src_dir + \"/dog\")\n",
    "\n",
    "    for cat in all_cats:\n",
    "        ftn(src_dir + \"/cat/\" + cat, dst_dir + \"/cat/\" + cat, level)\n",
    "\n",
    "    for dog in all_dogs:\n",
    "        ftn(src_dir + \"/dog/\" + dog, dst_dir + \"/dog/\" + dog, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "304971e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: 1. Processing noise level:0.05\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 153s 2s/step - loss: 13.5091 - accuracy: 0.9185\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.1\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 154s 2s/step - loss: 22.8581 - accuracy: 0.8650\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.15\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 2016s 32s/step - loss: 31.7887 - accuracy: 0.8295\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.2\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 149s 2s/step - loss: 39.7307 - accuracy: 0.7935\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.25\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 156s 2s/step - loss: 46.1561 - accuracy: 0.7405\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.3\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 152s 2s/step - loss: 52.2034 - accuracy: 0.7085\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.4\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 155s 2s/step - loss: 55.7830 - accuracy: 0.6625\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.5\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 188s 3s/step - loss: 52.7113 - accuracy: 0.6285\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.6\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 154s 2s/step - loss: 45.2014 - accuracy: 0.6080\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.7\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 154s 2s/step - loss: 31.4409 - accuracy: 0.6065\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.8\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save sample image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 216s 3s/step - loss: 19.3030 - accuracy: 0.6020\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.9\n",
      "DEBUG: 2. Creating Images\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pm/qn6ytz3x4hn6_8dbh2l8dk6m0000gn/T/ipykernel_47931/1607895492.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Step 2: Copy over the image after adding noise and setup as dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcreate_altered_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_altered_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_noisy_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtest_noisy_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_dataset_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_altered_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pm/qn6ytz3x4hn6_8dbh2l8dk6m0000gn/T/ipykernel_47931/1528259583.py\u001b[0m in \u001b[0;36mcreate_altered_images\u001b[0;34m(src_dir, dst_dir, ftn, level)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_cats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mftn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/cat/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/cat/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_dogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pm/qn6ytz3x4hn6_8dbh2l8dk6m0000gn/T/ipykernel_47931/1528259583.py\u001b[0m in \u001b[0;36mcreate_noisy_image\u001b[0;34m(src_img, dst_img, noise_level)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Remove colours from image at the given random points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Save the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now we apply the model to varying levels of noise in the image.\n",
    "# Noise profile - defined noise level at each step - shoul be between 0 and 1.0.\n",
    "noise_levels = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                \n",
    "for lvl in noise_levels:\n",
    "    print(f\"DEBUG: 1. Processing noise level:{lvl}\")\n",
    "\n",
    "    np.random.seed(2179784)  # To ensure reproducible.\n",
    "\n",
    "    # Step 1: Clear out the ./cats_vs_dogs/test_noisy directories\n",
    "    os.system('rm ./cats_vs_dogs/test_altered/cat/*.jpg')\n",
    "    os.system('rm ./cats_vs_dogs/test_altered/dog/*.jpg')\n",
    "\n",
    "    print(\"DEBUG: 2. Creating Images\")\n",
    "\n",
    "    # Step 2: Copy over the image after adding noise and setup as dataset\n",
    "    create_altered_images(test_dir, test_altered_dir, create_noisy_image, lvl)\n",
    "    test_noisy_dataset = image_dataset_from_directory(test_altered_dir, image_size=(180, 180), batch_size=32)\n",
    "\n",
    "    print(\"DEBUG: 3. Save sample image\")\n",
    "\n",
    "    # Step 3: Save example image\n",
    "    sample_image.append(io.imread(test_altered_dir + \"/cat/cat.1500.jpg\"))\n",
    "\n",
    "    print(\"DEBUG: 4. Running Model\")\n",
    "\n",
    "    # Step 4: Run model against images\n",
    "    test_loss, test_acc = test_model.evaluate(test_noisy_dataset)\n",
    "\n",
    "    print(\"DEBUG: 5. Save Results\")\n",
    "\n",
    "    # Step 5: Save results\n",
    "    noise_level.append(lvl)              # Noise level saved\n",
    "    accuracy.append(round(test_acc, 4))  # Model accuracy saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images with varying degrees of noise\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "fig.suptitle('Degradation of Image with Increasing Noise Levels')\n",
    "for i in range(len(sample_image)):\n",
    "    ax = fig.add_subplot(5, 3, i+1)\n",
    "    ax.set_title(f\"Noise Level: {noise_level[i]}\")\n",
    "    io.imshow(sample_image[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3620c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the results of the effect of noise on the model's ability to classify images.\n",
    "\n",
    "plt.plot(noise_level, accuracy, '-o')\n",
    "plt.xlabel(\"Noise Level\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.title(\"Model Accuracy Vs. Noise Level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780b4d8",
   "metadata": {},
   "source": [
    "## Now Start the Fading Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset saved values:\n",
    "fade_factor = []\n",
    "accuracy = []\n",
    "sample_image = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we apply the model to varying levels of faded image.\n",
    "# Fade levels:\n",
    "fade_levels = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "                \n",
    "for lvl in fade_levels:\n",
    "    print(f\"DEBUG: 1. Processing fade level:{lvl}\")\n",
    "\n",
    "    np.random.seed(2179784)  # To ensure reproducible.\n",
    "\n",
    "    # Step 1: Clear out the ./cats_vs_dogs/test_noisy directories\n",
    "    os.system('rm ./cats_vs_dogs/test_altered/cat/*.jpg')\n",
    "    os.system('rm ./cats_vs_dogs/test_altered/dog/*.jpg')\n",
    "\n",
    "    print(\"DEBUG: 2. Creating Images\")\n",
    "\n",
    "    # Step 2: Copy over the image after adding noise and setup as dataset\n",
    "    create_altered_images(test_dir, test_altered_dir, fade_image, lvl)\n",
    "    test_faded_dataset = image_dataset_from_directory(test_altered_dir, image_size=(180, 180), batch_size=32)\n",
    "\n",
    "    print(\"DEBUG: 3. Save sample image\")\n",
    "\n",
    "    # Step 3: Save example image\n",
    "    sample_image.append(io.imread(test_altered_dir + \"/cat/cat.1500.jpg\"))\n",
    "\n",
    "    print(\"DEBUG: 4. Running Model\")\n",
    "\n",
    "    # Step 4: Run model against images\n",
    "    test_loss, test_acc = test_model.evaluate(test_faded_dataset)\n",
    "\n",
    "    print(\"DEBUG: 5. Save Results\")\n",
    "\n",
    "    # Step 5: Save results\n",
    "    fade_factor.append(lvl)              # Fading level saved\n",
    "    accuracy.append(round(test_acc, 4))  # Model accuracy saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "fig.suptitle('Degradation of Image with Increasing \"Fade\" Factors')\n",
    "for i in range(len(sample_image)):\n",
    "    ax = fig.add_subplot(4, 3, i+1)\n",
    "    ax.set_title(f\"Fade Factor: {fade_factor[i]}\")\n",
    "    io.imshow(sample_image[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c879a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results of the effect of fading on the model's ability to classify images.\n",
    "\n",
    "plt.plot(fade_factor, accuracy, '-o')\n",
    "plt.xlabel(\"Fade Factor\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.title(\"Model Accuracy Vs. Fading Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = datetime.datetime.now()\n",
    "\n",
    "print (\"Current date and time = %s\" % e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
