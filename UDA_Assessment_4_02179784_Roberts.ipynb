{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10efe37",
   "metadata": {},
   "source": [
    "# Project for UDA Assessment 4\n",
    "## Author: 02179784 (Mark Roberts)\n",
    "\n",
    "<B>Project Description:</B><BR>\n",
    "The objective of this project is to create a simple framework to test how well image classification models perform when presented with noisey images.  The idea is that different models can be swapped-in/out and tested with minimal changes.\n",
    "\n",
    "In this particular implementation of the framework:\n",
    " - we use a model that has been pre-trained to classify non-noisy images with an accurancy of over 97%.<BR>\n",
    "    This model was created using the guidance provided in chapter 8 of [1], and is based on refining an already pretrained model.<BR>\n",
    "    The refining of the model has been omitted here as it took several hours to build this model!\n",
    " - all images used in the training, validation and testing of this model are cat and dog images taken from the Kaggle website: [Cat and Dog Images](https://kaggle.com/competitions/dogs-vs-cats/data).\n",
    " - testing will be done using uniform random noise, but this could be easily replaced by other noise patterns (e.g. Gaussian) if desired.  The image dataset consists of 2000 images - 1000 cat and 1000 dog images.\n",
    "\n",
    "\n",
    "<B>General Information:</B><BR>\n",
    " - This script was run on a Macbook Pro. with 16 GB of RAM, 3.1 GHz Quad-Core Intel Core i7.\n",
    " - The total run time of the Jupyter notebook was (approx) 120 seconds.\n",
    " - The Github repository for all code and datasets can be obtained by cloning the repository:<BR>\n",
    "              git@github.com:Mark12481632/UDA_Assessment_4_02179784_Roberts.git\n",
    " - The model used to classify the images is built on __TensorFlow__ and __Keras__.\n",
    " - __Altered images need to be saved to disk - so write permission for the notebook is required!!__\n",
    "    \n",
    "<B>References:</B><BR>\n",
    "    \n",
    "    [1] - Deep Learning with Python (Francios Chollet, Manning Publications, ISBN-13: 978-1617296864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01720d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time = 2022-12-26 17:38:27.212515\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "import datetime\n",
    "\n",
    "e = datetime.datetime.now()\n",
    "\n",
    "print (\"Current date and time = %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f0a244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 17:38:29.197920: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load in the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input, Model, Sequential\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7ad977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 17:38:35.482135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Location of non-noisy and noisy images:\n",
    "test_dir = \"./cats_vs_dogs/test\"\n",
    "test_noisy_dir = \"./cats_vs_dogs/test_noisy\"\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(180, 180), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2a0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable that stores accuracy and level of noise in images\n",
    "noise_level = []\n",
    "accuracy = []\n",
    "sample_image = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5309071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "63/63 [==============================] - 156s 2s/step - loss: 3.5702 - accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "# Test on Original images without any noise.\n",
    "# The image that was trained has been saved as \"feature_extraction_with_data_augmentation.keras\"\n",
    "\n",
    "test_model = load_model(\"feature_extraction_with_data_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "\n",
    "noise_level.append(0)                                          # Noise level saved\n",
    "accuracy.append(round(test_acc, 4))                            # Model accuracy saved\n",
    "sample_image.append(io.imread(test_dir + \"/cat/cat.1500.jpg\")) # Sample image saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe4227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_image(src_img, dst_img, noise_level):\n",
    "    \"\"\"\n",
    "    This function takes a single image 'src_img' and addes noise to it as defoned\n",
    "    by the 'noise_level' parameter.  The noisy image is then written to 'dst_img'.\n",
    "    Nothing is returned.\n",
    "    \"\"\"\n",
    "    # Read in image into Numpy array\n",
    "    img = io.imread(src_img)\n",
    "\n",
    "    # Generate a matrix of random data (0=>1) in same shape as image\n",
    "    noise_matrix = np.random.uniform(low=0, high=1.0,\n",
    "                                     size=(img.shape[0]*img.shape[1])).reshape(img.shape[0], img.shape[1])\n",
    "    # Where does the data exceed the \"threshold\"\n",
    "    noise_matrix = np.where(noise_matrix < noise_level)\n",
    "\n",
    "    # Remove colours from image at the given random points\n",
    "    for (x,y) in zip(noise_matrix[0], noise_matrix[1]):\n",
    "        img[x, y, 0:3] = 0\n",
    "\n",
    "    # Save the image\n",
    "    io.imsave(dst_img, img)\n",
    "\n",
    "\n",
    "def create_noisy_images(src_dir, dst_dir, noise_level):\n",
    "    \"\"\"\n",
    "    This function copies over the images from a 'src_dir' to a 'dst_dir' after random\n",
    "    noise has been added to the image.  The 'noise_level' determines the level of noise (0->1).\n",
    "    Nothing is returned.\n",
    "    \"\"\"\n",
    "    all_cats = os.listdir(src_dir + \"/cat\")\n",
    "    all_dogs = os.listdir(src_dir + \"/dog\")\n",
    "\n",
    "    for cat in all_cats:\n",
    "        create_noisy_image(src_dir + \"/cat/\" + cat, dst_dir + \"/cat/\" + cat, noise_level)\n",
    "\n",
    "    for dog in all_dogs:\n",
    "        create_noisy_image(src_dir + \"/dog/\" + dog, dst_dir + \"/dog/\" + dog, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5361e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: 1. Processing noise level:0.05\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 160s 3s/step - loss: 13.5091 - accuracy: 0.9185\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.1\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 153s 2s/step - loss: 22.8581 - accuracy: 0.8650\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.15\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 2065s 33s/step - loss: 31.7887 - accuracy: 0.8295\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.2\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 602s 10s/step - loss: 39.7307 - accuracy: 0.7935\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.25\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 628s 10s/step - loss: 46.1561 - accuracy: 0.7405\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.3\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 1594s 26s/step - loss: 52.2034 - accuracy: 0.7085\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.4\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 4862s 78s/step - loss: 55.7830 - accuracy: 0.6625\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.5\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 158s 3s/step - loss: 52.7113 - accuracy: 0.6285\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.6\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 159s 3s/step - loss: 45.2014 - accuracy: 0.6080\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.7\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 167s 3s/step - loss: 31.4409 - accuracy: 0.6065\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.8\n",
      "DEBUG: 2. Creating Images\n",
      "Found 2000 files belonging to 2 classes.\n",
      "DEBUG: 3. Save image\n",
      "DEBUG: 4. Running Model\n",
      "63/63 [==============================] - 169s 3s/step - loss: 19.3030 - accuracy: 0.6020\n",
      "DEBUG: 5. Save Results\n",
      "DEBUG: 1. Processing noise level:0.9\n",
      "DEBUG: 2. Creating Images\n"
     ]
    }
   ],
   "source": [
    "# Now we apply the model to varying levels of noise in the image.\n",
    "# Noise profile - defined noise level at each step - shoul be between 0 and 1.0.\n",
    "noise_levels = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                \n",
    "for lvl in noise_levels:\n",
    "    print(f\"DEBUG: 1. Processing noise level:{lvl}\")\n",
    "\n",
    "    np.random.seed(2179784)  # To ensure reproducible.\n",
    "\n",
    "    # Step 1: Clear out the ./cats_vs_dogs/test_noisy directories\n",
    "    os.system('rm ./cats_vs_dogs/test_noisy/cat/*')\n",
    "    os.system('rm ./cats_vs_dogs/test_noisy/dog/*')\n",
    "\n",
    "    print(\"DEBUG: 2. Creating Images\")\n",
    "\n",
    "    # Step 2: Copy over the image after adding noise and setup as dataset\n",
    "    create_noisy_images(test_dir, test_noisy_dir, lvl)\n",
    "    test_noisy_dataset = image_dataset_from_directory(test_noisy_dir, image_size=(180, 180), batch_size=32)\n",
    "\n",
    "    print(\"DEBUG: 3. Save image\")\n",
    "\n",
    "    # Step 3: Save example image\n",
    "    sample_image.append(io.imread(test_noisy_dir + \"/cat/cat.1500.jpg\"))\n",
    "\n",
    "    print(\"DEBUG: 4. Running Model\")\n",
    "\n",
    "    # Step 4: Run model against images\n",
    "    test_loss, test_acc = test_model.evaluate(test_noisy_dataset)\n",
    "\n",
    "    print(\"DEBUG: 5. Save Results\")\n",
    "\n",
    "    # Step 5: Save results\n",
    "    noise_level.append(lvl)              # Noise level saved\n",
    "    accuracy.append(round(test_acc, 4))  # Model accuracy saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images with varying degrees of noise\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "fig.suptitle('Degradation of Image with Increasing Noise Levels')\n",
    "for i in range(len(sample_image)):\n",
    "    ax_1 = fig.add_subplot(5, 3, i+1)\n",
    "    io.imshow(sample_image[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05672291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the results of the effect of noise on the model's ability to classify images.\n",
    "\n",
    "plt.plot(noise_level, accuracy, '-o')\n",
    "plt.xlabel(\"Noise Level\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.title(\"Model Accuracy Vs. Noise Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = datetime.datetime.now()\n",
    "\n",
    "print (\"Current date and time = %s\" % e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
