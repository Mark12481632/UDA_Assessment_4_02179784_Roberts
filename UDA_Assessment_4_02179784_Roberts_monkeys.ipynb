{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e24c92",
   "metadata": {},
   "source": [
    "# Project for UDA Assessment 4\n",
    "## Author: 02179784 (Mark Roberts)\n",
    "\n",
    "<B>Project Description:</B><BR>\n",
    "The intention of this project is to investigate how practical it is to use a \"generic\" model for image classification.  The idea is to take general JPEG image files and transform them into a \"standard\" format using the steps:\n",
    " - Converted image from colour to greyscale (pixels have a value in the range: 0-255).\n",
    " - Resize images to a standard size (i.e. 350,350).\n",
    "\n",
    "and then train a simple classification model on these \"standardized\" images.\n",
    "\n",
    "This analysis has been, like this notebook, split into the following sections:\n",
    " - Benchmark the classification method using the original, unaltered colour images.\n",
    " - Standardize the image data.\n",
    " - Building the model\n",
    " - Determining accuracy of the model\n",
    " - Checking how accuracy of the model varies with image size.\n",
    "\n",
    "Details of the dataset, taken from Kaggle, can be found here: [Monkey Images](https://www.kaggle.com/datasets/slothkong/10-monkey-species).<BR><BR>\n",
    "It should be noted that only 4 of the 10 original monkey image categories have been used.  This is due to the limitations that have been placed on the dataset size (100MB).\n",
    "\n",
    "Note that the category of monkey is given by the directory in which the picture is located (e.g. /n0).  The mapping from directories to monkey type is given here:\n",
    "\n",
    "| Label | Latin Name | Common Name | Train Images | Validation Images |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| n0 | alouatta_palliata | mantled_howler | 105 | 26 |\n",
    "| n1 | erythrocebus_patas | patas_monkey | 111 | 28 |\n",
    "| n2 | cacajao_calvus | bald_uakari | 110 | 27 |\n",
    "| n3 | macaca_fuscata | japanese_macaque | 122 | 30 |\n",
    "\n",
    "Further details of the project can be found in the PDF associated with the assessment.\n",
    "\n",
    "    \n",
    "<B>General Information:</B><BR>\n",
    " - This script was run on a Macbook Pro. with 32 GB of RAM.\n",
    " - The total run time of the Jupyter notebook was (approx) 120 seconds.\n",
    " - The Github repository for all code and datasets can be obtained by cloning the repository:\n",
    "[GitHub-Repo](git@github.com:Mark12481632/UDA_Assessment_4_02179784_Roberts.git)\n",
    " - <B>The environment running the note book must allow for the creation of directories!!</B>\n",
    "    \n",
    "https://www.kaggle.com/datasets/niteshfre/chessman-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25d3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we will use:\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import data, io, color\n",
    "from IPython.display import display # to display images\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "059b274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common variables:\n",
    "\n",
    "# Directories for datasets:\n",
    "photo_root = \"./monkeys\"\n",
    "\n",
    "source_training_photos = photo_root + \"/source_dataset/training\"\n",
    "dest_training_photos = photo_root + \"/derived_dataset/training\"\n",
    "\n",
    "source_validation_photos = photo_root + \"/source_dataset/validation\"\n",
    "dest_validation_photos = photo_root + \"/derived_dataset/validation\"\n",
    "\n",
    "# Restrict our analysis to following monkey categories:\n",
    "monkey_groups = [\"n0\", \"n1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "93b3c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions:\n",
    "\n",
    "def image_as_np_vector(file):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    img_data = io.imread(file)\n",
    "    vec = np.reshape(img_data, -1)\n",
    "    return(vec)\n",
    "\n",
    "\n",
    "def create_bw_photo(infile, outfile, height=350, width=350):\n",
    "    \"\"\"\n",
    "    This \n",
    "    \"\"\"\n",
    "    img = Image.open(infile)\n",
    "\n",
    "    img = img.convert(\"L\").resize((height, width))\n",
    "    bw_image = np.array(img.getdata(), dtype = np.uint8).reshape(height, width)\n",
    "\n",
    "    # Sanity check\n",
    "    if img.size != bw_image.shape:\n",
    "        print(f\"ISSUE when sizing {in_dir + file}\")\n",
    "\n",
    "    io.imsave(outfile, bw_image)\n",
    "\n",
    "\n",
    "def read_in_images(img_loc, group_list=monkey_groups):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for group in group_list:\n",
    "        group_files = os.listdir(img_loc + \"/\" + group)\n",
    "\n",
    "        for file in group_files:\n",
    "            img_vec = image_as_np_vector(img_loc + \"/\" + group + \"/\" + file)\n",
    "            data_list.append(img_vec)\n",
    "            label_list.append(group)\n",
    "\n",
    "    data = np.concatenate(data_list, axis=0)#.reshape(len(label_list),-1)\n",
    "    labels = np.array(label_list)\n",
    "\n",
    "    print('A.', len(label_list), label_list)\n",
    "    print('B.', len(data_list), data_list[1].shape)\n",
    "    print('C.', len(data.tobytes()))\n",
    "\n",
    "    return((data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9cdde",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "In order to get a basline metric on how well we can categorize the monkey images let's first see how well the\n",
    "model can work on the original colour images of the monkeys.\n",
    "\n",
    "The simplest classifier, that didn't involke Deep Learning, was the SGDClassifier.  This has "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8486a79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. 216 ['n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n0', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1', 'n1']\n",
      "B. 216 (405000,)\n",
      "C. 544300614\n",
      "1 111 (111,) <class 'numpy.ndarray'> (496500,)\n",
      "2 111\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pm/qn6ytz3x4hn6_8dbh2l8dk6m0000gn/T/ipykernel_45542/1668829550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Test data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Read in images and label them, ready for training and validation:\n",
    "\n",
    "# Train data:\n",
    "train_data, train_labels = read_in_images(source_training_photos)\n",
    "\n",
    "# Shuffle data..\n",
    "np.random.seed(1234) # Ensure reproducable...\n",
    "shuffle_index = np.random.choice(len(label_list), size=len(label_list), replace=False)\n",
    "\n",
    "train_data = train_data[shuffle_index]\n",
    "train_labels = train_labels[shuffle_index]\n",
    "\n",
    "print('1', len(train_data), train_data.shape, type(data_list[1]), data_list[1].shape)\n",
    "print('2', len(label_list))\n",
    "print('3', train_data[0:5, 0:5])\n",
    "\n",
    "# Test data:\n",
    "test_data, test_labels = read_in_images(source_validation_photos)\n",
    "\n",
    "print(test_data[0:5, 0:5])\n",
    "print(test_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5dbd6f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 550, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = io.imread(\"./monkeys/source_dataset/training/n0/n0018.jpg\")\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d3ca8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(max_iter=25000, random_state=123, tol=1e-05)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train using the colour images\n",
    "sgd_clf = SGDClassifier(random_state=123, max_iter=25000, tol=1e-5)\n",
    "\n",
    "# Now look at how well it works on test data\n",
    "sgd_clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2f05093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = sgd_clf.predict(test_data)\n",
    "\n",
    "print(len(predicted_labels))\n",
    "print((predicted_labels==test_labels).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76335d03",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "In this step we will convert all coloured monkey photos:\n",
    " - into black & white photos\n",
    " - set to fixed size (150, 150)\n",
    "\n",
    "This step took less than 20 seconds to complete.<BR><BR>\n",
    "Kaggle provides two directories, one containing training monkey images and one containing test monkey images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for group in monkey_groups:\n",
    "    # Process \"training\" dataset:\n",
    "    # Create B&W output directory\n",
    "    os.makedirs(dest_training_photos + group, exist_ok=True)\n",
    "        \n",
    "    # What are the colour photo files\n",
    "    group_files = os.listdir(source_training_photos + group)\n",
    "    print(f\"DEBUG: Processing Group (Training): {group}, with {len(group_files)} files\")\n",
    "\n",
    "    in_dir = source_training_photos + group + \"/\"\n",
    "    out_dir = dest_training_photos + group + \"/\"\n",
    "\n",
    "    for file in group_files:\n",
    "        create_bw_photo(in_dir + file, out_dir + file)\n",
    "\n",
    "\n",
    "    # Process \"validation\" dataset:\n",
    "    # Create B&W output directory\n",
    "    os.makedirs(dest_validation_photos + group, exist_ok=True)\n",
    "\n",
    "    # What are the colour photo files        \n",
    "    group_files = os.listdir(source_validation_photos + group)\n",
    "    print(f\"DEBUG: Processing Group (Validation): {group}, with {len(group_files)} files\")\n",
    "\n",
    "    in_dir = source_validation_photos + group + \"/\"\n",
    "    out_dir = dest_validation_photos + group + \"/\"\n",
    "\n",
    "    for file in group_files:\n",
    "        create_bw_photo(in_dir + file, out_dir + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see an example of a colour image of a monkey and the corresponding black & white image:\n",
    "orig_img = io.imread(source_training_photos + \"/n0/n0018.jpg\")\n",
    "\n",
    "# Show \"standardized\" version of same image.\n",
    "new_img = io.imread(dest_training_photos + \"/n0/n0018.jpg\")\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "fig.suptitle('Corresponding Colour and Black & White Images of a Monkey')\n",
    "ax_1 = fig.add_subplot(2,2,1)\n",
    "io.imshow(orig_img)\n",
    "ax_2 = fig.add_subplot(2,2,2)\n",
    "io.imshow(new_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate BW images into labelled dataset:\n",
    "\n",
    "np.random.seed(1234) # Ensure reproducable...\n",
    "\n",
    "def image_as_np_vector(file):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    img_data = io.imread(file)\n",
    "    vec = np.reshape(img_data, -1)\n",
    "    return(vec)\n",
    "    \n",
    "# Train data:\n",
    "data_list = []\n",
    "label_list = []\n",
    "for group in monkey_groups:\n",
    "    group_files = os.listdir(dest_training_photos + group)\n",
    "    for file in group_files:\n",
    "        img_vec = image_as_np_vector(dest_training_photos + group + \"/\" + file)\n",
    "        data_list.append(img_vec.tolist())\n",
    "        label_list.append(group[1:]) # Remove preceeding '/'\n",
    "\n",
    "# Shuffle data..\n",
    "shuffle_index = np.random.choice(len(label_list), size=len(label_list), replace=False)\n",
    "\n",
    "train_data = np.concatenate(data_list, axis=0)[shuffle_index]\n",
    "train_labels = np.array(label_list)[shuffle_index]\n",
    "\n",
    "print(len(train_data), train_data.shape, type(data_list[1]))\n",
    "print(train_data[0:5])\n",
    "print(train_labels[0:5])\n",
    "\n",
    "\"\"\"\n",
    "# Test data:\n",
    "data_list = []\n",
    "label_list = []\n",
    "for group in monkey_groups:\n",
    "    group_files = os.listdir(dest_validation_photos + group)\n",
    "    for file in group_files:\n",
    "        img_vec = image_as_np_vector(dest_validation_photos + group + \"/\" + file)\n",
    "        data_list.append(img_vec)\n",
    "        label_list.append(group[1:]) # Remove preceeding '/'\n",
    "\n",
    "# Shuffle data..\n",
    "shuffle_index = np.random.choice(len(label_list), size=len(label_list), replace=False)\n",
    "\n",
    "test_data = np.concatenate(data_list, axis=0)[shuffle_index]\n",
    "test_labels = np.array(label_list)[shuffle_index]\n",
    "\n",
    "print(test_data[0:5, 0:5])\n",
    "print(test_labels[0:5])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d454623",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "In this step we need to create a model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee709c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)\n",
    "sgd_clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = sgd_clf.predict(test_data)\n",
    "\n",
    "print(len(predicted_labels))\n",
    "print((predicted_labels==test_labels).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23432281",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = ['n0', 'n1', 'n2', 'n3']\n",
    "\n",
    "conf_mat = confusion_matrix(test_labels, predicted_labels)\n",
    "print(conf_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c358a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
